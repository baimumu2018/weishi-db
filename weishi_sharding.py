import json
import re
import os


# ================= é…ç½®åŒºåŸŸ =================
input_file = r'/Users/baimumu/Desktop/weishi-db/weishi.txt'      # ä½ çš„ç»æ–‡TXT
output_prefix = r'/Users/baimumu/Desktop/weishi-db/weishi_part'   # è¾“å‡ºçš„JSON
config_file = r'/Users/baimumu/Desktop/weishi-db/weishi_config.json'  # ğŸ†• æ–°å¢ï¼šç´¢å¼•é…ç½®æ–‡ä»¶å
index_file = r'/Users/baimumu/Desktop/weishi-dbweishi_index.json'  # ğŸ†• æ–°å¢ï¼šç´¢å¼•æ–‡ä»¶å

chunk_size = 3000

# ===========================================

def extract_book_title(line):
    match = re.search(r'ã€Š(.*?)ã€‹', line)
    if match: return f"ã€Š{match.group(1)}ã€‹"
    return None


def is_junk_line(line):
    if "å¤§æ­£è—" in line or "No." in line or "P0279" in line: return True
    if "è¯‘" in line and len(line) < 20: return True
    if re.search(r'å·ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]', line): return True
    if line.startswith('-') or line.strip().isdigit(): return True
    return False


def convert():
    print(f"ğŸ§¹ æ­£åœ¨è¯»å– {input_file} ...")
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except:
        with open(input_file, 'r', encoding='gbk') as f:
            lines = f.readlines()

    all_data = []
    current_book = "å”¯è¯†ç»å…¸"
    global_count = 0

    print("ğŸ”„ æ­£åœ¨å¤„ç†æ•°æ®...")
    for line in lines:
        line = line.strip()
        if not line: continue
        new_title = extract_book_title(line)
        if new_title:
            current_book = new_title
            continue
        if is_junk_line(line): continue

        content = line.replace('\u3000', '').replace('[00]', '')
        content = re.sub(r'([ã€‚ï¼Ÿï¼ï¼›])', r'\1|SPLIT|', content)
        sentences = content.split('|SPLIT|')

        for s in sentences:
            s = s.strip()
            if len(s) > 5 and not re.search(r'[a-zA-Z0-9]{3,}', s):
                global_count += 1
                all_data.append({"id": global_count, "text": s, "source": current_book})

    # === åˆ‡ç‰‡ & å»ºç«‹ç´¢å¼• ===
    total_parts = (len(all_data) // chunk_size) + 1
    print(f"ğŸ“Š å…± {len(all_data)} æ¡ï¼Œåˆ‡åˆ†ä¸º {total_parts} ä¸ªæ–‡ä»¶...")

    book_index = {}  # ğŸ“– ç´¢å¼•å­—å…¸ï¼š {"ã€Šæˆå”¯è¯†è®ºã€‹": [0, 1, 2], ...}

    for i in range(total_parts):
        filename = f"{output_prefix}_{i}.json"
        start = i * chunk_size
        end = start + chunk_size
        batch = all_data[start:end]
        if not batch: continue

        # è®°å½•è¿™ä¸€æ‰¹æ–‡ä»¶é‡ŒåŒ…å«å“ªäº›ä¹¦
        for item in batch:
            b_name = item['source']
            if b_name not in book_index:
                book_index[b_name] = set()
            book_index[b_name].add(i)  # æŠŠå½“å‰æ–‡ä»¶ç¼–å·è®°ä¸‹æ¥

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(batch, f, ensure_ascii=False, indent=2)

    # è½¬æ¢ set ä¸º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
    final_index = {k: list(v) for k, v in book_index.items()}

    # ä¿å­˜ Config (æ€»æ•°)
    config_data = {"max_index": total_parts - 1, "total_count": len(all_data)}
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_data, f, ensure_ascii=False, indent=2)

    # ä¿å­˜ Index (ç´¢å¼•)
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(final_index, f, ensure_ascii=False, indent=2)

    print("-" * 30)
    print(f"âœ… ç´¢å¼•å·²ç”Ÿæˆï¼")
    print(f"ğŸ“š ä½ çš„ç»ä¹¦åˆ—è¡¨: {list(final_index.keys())}")
    print(f"ğŸš€ è¯·è¿è¡Œ update.command ä¸Šä¼ æ‰€æœ‰æ–°æ–‡ä»¶ï¼")


if __name__ == '__main__':
    convert()